{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "18e1aecb-9685-408c-bcbe-fcb6904193d0",
      "cell_type": "code",
      "source": "# Optional: Create the CSV file using Python\ncontent = \"\"\"\norder_id,region,product,quantity,price\n2001,North,Keyboard,2,1500\n2002,South,Mouse,1,500\n2003,North,Monitor,1,12000\n2004,East,Mouse,4,500\n2005,West,Keyboard,1,1500\n2006,South,Monitor,,12000\n2007,East,Keyboard,3,1500\n2008,West,Mouse,2,500\n\"\"\"\n\nwith open(\"regional_sales.csv\", \"w\") as file:\n    file.write(content)\n\nprint(\"regional_sales.csv created successfully!\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "regional_sales.csv created successfully!\n"
        }
      ],
      "execution_count": 60
    },
    {
      "id": "4570dcb3-898c-424e-985d-0cec469e59cc",
      "cell_type": "code",
      "source": "import pandas as pd\ndf = pd.read_csv(\"regional_sales.csv\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 61
    },
    {
      "id": "0fe8696d-11df-4bff-a6bd-5afd223910ab",
      "cell_type": "code",
      "source": "print(df)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "   order_id region   product  quantity  price\n0      2001  North  Keyboard       2.0   1500\n1      2002  South     Mouse       1.0    500\n2      2003  North   Monitor       1.0  12000\n3      2004   East     Mouse       4.0    500\n4      2005   West  Keyboard       1.0   1500\n5      2006  South   Monitor       NaN  12000\n6      2007   East  Keyboard       3.0   1500\n7      2008   West     Mouse       2.0    500\n"
        }
      ],
      "execution_count": 62
    },
    {
      "id": "8982d1d4-e015-431d-8662-a156c603234d",
      "cell_type": "code",
      "source": "print(\"Dataset Shape:\", df.shape)\nprint(\"\\nFirst few rows:\")\nprint(df.head())\nprint(\"\\nData Types:\")\nprint(df.dtypes)\nprint(\"\\nMissing Values:\")\nprint(df.isnull().sum())\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Dataset Shape: (8, 5)\n\nFirst few rows:\n   order_id region   product  quantity  price\n0      2001  North  Keyboard       2.0   1500\n1      2002  South     Mouse       1.0    500\n2      2003  North   Monitor       1.0  12000\n3      2004   East     Mouse       4.0    500\n4      2005   West  Keyboard       1.0   1500\n\nData Types:\norder_id      int64\nregion       object\nproduct      object\nquantity    float64\nprice         int64\ndtype: object\n\nMissing Values:\norder_id    0\nregion      0\nproduct     0\nquantity    1\nprice       0\ndtype: int64\n"
        }
      ],
      "execution_count": 63
    },
    {
      "id": "c9386336-58de-4e38-8092-21e020a42a3d",
      "cell_type": "code",
      "source": "clean_df = df.dropna(subset=[\"quantity\"])\nprint(f\"Rows before cleaning: {len(df)}\")\nprint(f\"Rows after cleaning: {len(clean_df)}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Rows before cleaning: 8\nRows after cleaning: 7\n"
        }
      ],
      "execution_count": 64
    },
    {
      "id": "be3083be-db17-4650-ae6b-e7326fd72504",
      "cell_type": "code",
      "source": "clean_df[\"quantity\"] = pd.to_numeric(clean_df[\"quantity\"], errors='coerce')\nclean_df[\"price\"] = pd.to_numeric(clean_df[\"price\"], errors='coerce')\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "<ipython-input-65-04120c9afc64>:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  clean_df[\"quantity\"] = pd.to_numeric(clean_df[\"quantity\"], errors='coerce')\n<ipython-input-65-04120c9afc64>:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  clean_df[\"price\"] = pd.to_numeric(clean_df[\"price\"], errors='coerce')\n"
        }
      ],
      "execution_count": 65
    },
    {
      "id": "e97944c8-4c24-4ed9-91d9-ba597ae0d443",
      "cell_type": "code",
      "source": "duplicates_before = clean_df.duplicated().sum()\nclean_df = clean_df.drop_duplicates()\nprint(f\"Duplicates removed: {duplicates_before}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Duplicates removed: 0\n"
        }
      ],
      "execution_count": 66
    },
    {
      "id": "7046d6dc-a683-41fa-835c-577cefb466e2",
      "cell_type": "code",
      "source": "print(\"\\nCleaned Dataset:\")\nprint(clean_df)\nprint(f\"\\nMissing values after cleaning:\\n{clean_df.isnull().sum()}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\nCleaned Dataset:\n   order_id region   product  quantity  price\n0      2001  North  Keyboard       2.0   1500\n1      2002  South     Mouse       1.0    500\n2      2003  North   Monitor       1.0  12000\n3      2004   East     Mouse       4.0    500\n4      2005   West  Keyboard       1.0   1500\n6      2007   East  Keyboard       3.0   1500\n7      2008   West     Mouse       2.0    500\n\nMissing values after cleaning:\norder_id    0\nregion      0\nproduct     0\nquantity    0\nprice       0\ndtype: int64\n"
        }
      ],
      "execution_count": 67
    },
    {
      "id": "7e4979da-c542-48fb-ba2f-eadb52dbed3a",
      "cell_type": "code",
      "source": "clean_df[\"revenue\"] = clean_df[\"quantity\"] * clean_df[\"price\"]\nprint(\"Dataset with revenue:\")\nprint(clean_df[[\"order_id\", \"region\", \"quantity\", \"price\", \"revenue\"]])\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Dataset with revenue:\n   order_id region  quantity  price  revenue\n0      2001  North       2.0   1500   3000.0\n1      2002  South       1.0    500    500.0\n2      2003  North       1.0  12000  12000.0\n3      2004   East       4.0    500   2000.0\n4      2005   West       1.0   1500   1500.0\n6      2007   East       3.0   1500   4500.0\n7      2008   West       2.0    500   1000.0\n"
        }
      ],
      "execution_count": 68
    },
    {
      "id": "e70378f8-239d-4cd5-a897-231c87d9f15a",
      "cell_type": "code",
      "source": "regional_summary = clean_df.groupby(\"region\").agg({\n    \"revenue\": \"sum\",\n    \"quantity\": \"sum\"\n}).reset_index()\n\nregional_summary.columns = [\"Region\", \"Total_Revenue\", \"Total_Quantity\"]\nprint(\"\\nRegional Summary:\")\nprint(regional_summary)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\nRegional Summary:\n  Region  Total_Revenue  Total_Quantity\n0   East         6500.0             7.0\n1  North        15000.0             3.0\n2  South          500.0             1.0\n3   West         2500.0             3.0\n"
        }
      ],
      "execution_count": 69
    },
    {
      "id": "66f518c3-f4a6-413c-9852-599072c0c8d5",
      "cell_type": "code",
      "source": "top_region = regional_summary.sort_values(\"Total_Revenue\", ascending=False).iloc[0]\nprint(f\"\\nTop-Performing Region:\")\nprint(f\"Region: {top_region['Region']}\")\nprint(f\"Total Revenue: {top_region['Total_Revenue']:,.2f}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\nTop-Performing Region:\nRegion: North\nTotal Revenue: 15,000.00\n"
        }
      ],
      "execution_count": 70
    },
    {
      "id": "bb5efa48-7594-43fb-88ee-0b1c3f9cb87d",
      "cell_type": "code",
      "source": "regional_summary_sorted = regional_summary.sort_values(\"Total_Revenue\", ascending=False)\nprint(\"\\nRegions Sorted by Revenue (High to Low):\")\nprint(regional_summary_sorted)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\nRegions Sorted by Revenue (High to Low):\n  Region  Total_Revenue  Total_Quantity\n1  North        15000.0             3.0\n0   East         6500.0             7.0\n3   West         2500.0             3.0\n2  South          500.0             1.0\n"
        }
      ],
      "execution_count": 71
    },
    {
      "id": "d075d3e5-6a3e-4568-b7dd-29d054a7e910",
      "cell_type": "code",
      "source": "low_performing = regional_summary[regional_summary[\"Total_Revenue\"] < 5000]\nprint(\"\\nLow-Performing Regions (Revenue < 5,000):\")\nprint(low_performing)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\nLow-Performing Regions (Revenue < 5,000):\n  Region  Total_Revenue  Total_Quantity\n2  South          500.0             1.0\n3   West         2500.0             3.0\n"
        }
      ],
      "execution_count": 72
    },
    {
      "id": "7a4d5c2b-1ecc-4c03-970f-628d694e400e",
      "cell_type": "code",
      "source": "regional_summary_sorted.to_csv(\"regional_revenue_summary.csv\", index=False)\nprint(\"Saved: regional_revenue_summary.csv\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Saved: regional_revenue_summary.csv\n"
        }
      ],
      "execution_count": 73
    },
    {
      "id": "c1a69d08-e5a1-45b0-b1e6-6701dd8536b9",
      "cell_type": "code",
      "source": "if len(low_performing) > 0:\n    low_performing.to_csv(\"low_performing_regions.csv\", index=False)\n    print(\"Saved: low_performing_regions.csv\")\nelse:\n    print(\"No low-performing regions found (all regions above threshold)\")\n    # Create empty file with headers\n    pd.DataFrame(columns=[\"Region\", \"Total_Revenue\", \"Total_Quantity\"]).to_csv(\n        \"low_performing_regions.csv\", index=False\n    )\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Saved: low_performing_regions.csv\n"
        }
      ],
      "execution_count": 74
    },
    {
      "id": "9289d6e2-9ea8-401a-8c3c-b8e94df4b175",
      "cell_type": "code",
      "source": "print(\"\\n=== Analysis Summary ===\")\nprint(f\"Total Regions Analyzed: {len(regional_summary)}\")\nprint(f\"Total Revenue Across All Regions: {regional_summary['Total_Revenue'].sum():,.2f}\")\nprint(f\"Average Revenue per Region: {regional_summary['Total_Revenue'].mean():,.2f}\")\nprint(f\"Top Region: {top_region['Region']} ({top_region['Total_Revenue']:,.2f})\")\nprint(f\"Low-Performing Regions: {len(low_performing)}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n=== Analysis Summary ===\nTotal Regions Analyzed: 4\nTotal Revenue Across All Regions: 24,500.00\nAverage Revenue per Region: 6,125.00\nTop Region: North (15,000.00)\nLow-Performing Regions: 2\n"
        }
      ],
      "execution_count": 75
    },
    {
      "id": "496d8cee-32dc-4a3f-8889-c1fcde2a0e5c",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "1fc49048-34de-4164-af18-aaf02fe2151d",
      "cell_type": "code",
      "source": "def analyze_regional_sales(input_file, revenue_threshold=5000):\n    \"\"\"\n    Analyze regional sales performance and generate insights.\n    \n    Args:\n        input_file (str): Path to the sales CSV file\n        revenue_threshold (float): Threshold for low-performing regions\n    \n    Returns:\n        tuple: (regional_summary, low_performing_regions)\n    \"\"\"\n    # Load data\n    df = pd.read_csv(input_file)\n    print(\"Step 1: Dataset loaded\")\n    \n    # Clean data\n    clean_df = df.dropna(subset=[\"quantity\"])\n    clean_df[\"quantity\"] = pd.to_numeric(clean_df[\"quantity\"], errors='coerce')\n    clean_df[\"price\"] = pd.to_numeric(clean_df[\"price\"], errors='coerce')\n    clean_df = clean_df.drop_duplicates()\n    print(\"Step 2: Data cleaned\")\n    \n    # Compute revenue\n    clean_df[\"revenue\"] = clean_df[\"quantity\"] * clean_df[\"price\"]\n    print(\"Step 3: Revenue calculated\")\n    \n    # Aggregate by region\n    regional_summary = clean_df.groupby(\"region\").agg({\n        \"revenue\": \"sum\",\n        \"quantity\": \"sum\"\n    }).reset_index()\n    regional_summary.columns = [\"Region\", \"Total_Revenue\", \"Total_Quantity\"]\n    regional_summary = regional_summary.sort_values(\"Total_Revenue\", ascending=False)\n    print(\"Step 4: Regional aggregations computed\")\n    \n    # Identify low-performing regions\n    low_performing = regional_summary[regional_summary[\"Total_Revenue\"] < revenue_threshold]\n    print(\"Step 5: Key insights identified\")\n    \n    # Generate outputs\n    regional_summary.to_csv(\"regional_revenue_summary.csv\", index=False)\n    if len(low_performing) > 0:\n        low_performing.to_csv(\"low_performing_regions.csv\", index=False)\n    else:\n        pd.DataFrame(columns=[\"Region\", \"Total_Revenue\", \"Total_Quantity\"]).to_csv(\n            \"low_performing_regions.csv\", index=False\n        )\n    print(\"Step 6: Output files generated\")\n    \n    # Display insights\n    top_region = regional_summary.iloc[0]\n    print(\"\\n=== Key Insights ===\")\n    print(f\"Top-Performing Region: {top_region['Region']} (Revenue: {top_region['Total_Revenue']:,.2f})\")\n    print(f\"Low-Performing Regions: {len(low_performing)}\")\n    if len(low_performing) > 0:\n        print(\"Regions needing attention:\")\n        for _, row in low_performing.iterrows():\n            print(f\"  - {row['Region']}: {row['Total_Revenue']:,.2f}\")\n    \n    return regional_summary, low_performing\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 76
    },
    {
      "id": "3e9d5a39-cb6c-43d7-8396-352eafdb987d",
      "cell_type": "code",
      "source": "regional_summary, low_performing = analyze_regional_sales(\"regional_sales.csv\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Step 1: Dataset loaded\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "<ipython-input-76-116197786317>:18: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  clean_df[\"quantity\"] = pd.to_numeric(clean_df[\"quantity\"], errors='coerce')\n<ipython-input-76-116197786317>:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  clean_df[\"price\"] = pd.to_numeric(clean_df[\"price\"], errors='coerce')\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Step 2: Data cleaned\nStep 3: Revenue calculated\nStep 4: Regional aggregations computed\nStep 5: Key insights identified\nStep 6: Output files generated\n\n=== Key Insights ===\nTop-Performing Region: North (Revenue: 15,000.00)\nLow-Performing Regions: 2\nRegions needing attention:\n  - West: 2,500.00\n  - South: 500.00\n"
        }
      ],
      "execution_count": 77
    },
    {
      "id": "8a029550-7ee0-4fb7-b27e-a5221c0bfd83",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}